{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/Lavabar/kaggle_Herbarium22/main/efficientnet.py\n!wget https://github.com/Lavabar/kaggle_Herbarium22/raw/2a66a174217fae8ac69da232f6e6dd5407faeeb0/checkpoint0_7000.pth","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:24.755871Z","iopub.execute_input":"2022-04-15T06:48:24.756361Z","iopub.status.idle":"2022-04-15T06:48:29.892740Z","shell.execute_reply.started":"2022-04-15T06:48:24.756270Z","shell.execute_reply":"2022-04-15T06:48:29.891530Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# PyTorch model and training necessities\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom efficientnet import EfficientNetB0, EfficientNetB3\n\nfrom torch.utils.tensorboard import SummaryWriter\n\n# Image datasets and image manipulation\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\n\n# Image display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom PIL import Image\n\ntorch.manual_seed(0)\nimages_path = '../input/herbarium-2022-fgvc9/train_images/'","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:29.895356Z","iopub.execute_input":"2022-04-15T06:48:29.895664Z","iopub.status.idle":"2022-04-15T06:48:32.370054Z","shell.execute_reply.started":"2022-04-15T06:48:29.895621Z","shell.execute_reply":"2022-04-15T06:48:32.369060Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:32.371891Z","iopub.execute_input":"2022-04-15T06:48:32.372215Z","iopub.status.idle":"2022-04-15T06:48:32.445249Z","shell.execute_reply.started":"2022-04-15T06:48:32.372170Z","shell.execute_reply":"2022-04-15T06:48:32.444197Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class FirstModelFeatureExtractor(object):\n    \n    def __init__(self, model_path):\n        self.model = torch.load(model_path)\n        self.model.eval()\n        \n    def __call__(self, sample):\n        res = self.model.feature_extractor(torch.unsqueeze(sample, 0).cuda())\n        #print(res.shape)\n        return torch.squeeze(res)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:32.448780Z","iopub.execute_input":"2022-04-15T06:48:32.449584Z","iopub.status.idle":"2022-04-15T06:48:32.458369Z","shell.execute_reply.started":"2022-04-15T06:48:32.449459Z","shell.execute_reply":"2022-04-15T06:48:32.457316Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Gather datasets and prepare them for consumption\ntransform = transforms.Compose([\n                                transforms.Resize((224, 224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,), (0.5,)),\n                                FirstModelFeatureExtractor('./checkpoint0_7000.pth')\n                            ])\n\nclass CategoryDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe_X, dataframe_Y, transform, keys):\n        self.dataframe = dataframe_X.merge(dataframe_Y)\n        self.transform = transform\n        self.keys = keys\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, index):\n        row = self.dataframe.iloc[index]\n        return (\n            transform(Image.open(images_path + row[\"file_name\"])).cuda(),\n            torch.tensor(self.keys[row[\"category_id\"]]).cuda()\n        )","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:32.460061Z","iopub.execute_input":"2022-04-15T06:48:32.460459Z","iopub.status.idle":"2022-04-15T06:48:36.178862Z","shell.execute_reply.started":"2022-04-15T06:48:32.460413Z","shell.execute_reply":"2022-04-15T06:48:36.177918Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def do_training(training_loader, validation_loader, net, family_id, n_epoch=1):\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.RMSprop(net.parameters(), lr=0.001)\n    \n    for epoch in range(n_epoch):  # loop over the dataset multiple times\n        running_loss = 0.0\n\n        for i, data in enumerate(training_loader, 0):\n            # basic training loop\n            inputs, labels = data\n            optimizer.zero_grad()\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            print('{}, Batch {}'.format(family_id, i + 1))\n            running_loss += loss.item()\n            if i % 50 == 49:# Every 50 mini-batches...\n                torch.save(net, f'./checkpoint{family_id}_{epoch}_{i+1}.pth')\n                # Check against the validation set\n                running_vloss = 0.0\n\n                net.train(False) # Don't need to track gradents for validation\n                for j, vdata in enumerate(validation_loader, 0):\n                    vinputs, vlabels = vdata\n                    voutputs = net(vinputs)\n                    vloss = criterion(voutputs, vlabels)\n                    running_vloss += vloss.item()\n                net.train(True) # Turn gradients back on for training\n\n                avg_loss = running_loss / 50\n                avg_vloss = running_vloss / len(validation_loader)\n\n                # Log the running loss averaged per batch\n                writer.add_scalars('Training vs. Validation Loss',\n                                { 'Training' : avg_loss, 'Validation' : avg_vloss },\n                                epoch * len(training_loader) + i)\n\n                running_loss = 0.0\n    print('Finished Training')\n    writer.flush()\n    \n    return net","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:36.180406Z","iopub.execute_input":"2022-04-15T06:48:36.180730Z","iopub.status.idle":"2022-04-15T06:48:36.194564Z","shell.execute_reply.started":"2022-04-15T06:48:36.180685Z","shell.execute_reply":"2022-04-15T06:48:36.193621Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nfam_ids = sorted(os.listdir('../input/herbarium22-family-split/dataset_fsplit/'))","metadata":{"execution":{"iopub.status.busy":"2022-04-15T06:48:36.196302Z","iopub.execute_input":"2022-04-15T06:48:36.196883Z","iopub.status.idle":"2022-04-15T06:48:36.314955Z","shell.execute_reply.started":"2022-04-15T06:48:36.196829Z","shell.execute_reply":"2022-04-15T06:48:36.313848Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for family_id in fam_ids[101:]:\n\n    train_X = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/train_X.csv')\n    validation_X = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/valid_X.csv')\n    train_Y = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/train_Y.csv')\n    validation_Y = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/valid_Y.csv')\n\n    n_categories = train_Y.nunique()['category_id']\n\n    keys = dict(zip(sorted(train_Y['category_id'].unique()), range(n_categories)))\n\n    train_dataset = CategoryDataset(train_X, train_Y, transform, keys)\n    validation_dataset = CategoryDataset(validation_X, validation_Y, transform, keys)\n\n    training_loader = torch.utils.data.DataLoader(train_dataset,\n                                                  batch_size=64,\n                                                  shuffle=True)\n\n\n    validation_loader = torch.utils.data.DataLoader(validation_dataset,\n                                                    batch_size=8,\n                                                    shuffle=False)\n\n    net = EfficientNetB0(in_sz=1536, out_sz=n_categories)\n    net.to(device)\n\n\n    # default `log_dir` is \"runs\" - we'll be more specific here\n    writer = SummaryWriter(f'runs/herb_experiment_f{family_id}')\n\n    net = do_training(training_loader, validation_loader, net, family_id)\n    torch.save(net, f'./checkpoint_{family_id}_final.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r -9 models_.zip ./checkpoint_*_final.pth","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}