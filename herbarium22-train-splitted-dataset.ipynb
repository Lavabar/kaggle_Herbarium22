{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9b2839",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:13.635841Z",
     "iopub.status.busy": "2022-04-16T19:36:13.635066Z",
     "iopub.status.idle": "2022-04-16T19:36:18.381875Z",
     "shell.execute_reply": "2022-04-16T19:36:18.380647Z"
    },
    "papermill": {
     "duration": 4.76721,
     "end_time": "2022-04-16T19:36:18.384931",
     "exception": false,
     "start_time": "2022-04-16T19:36:13.617721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-16 19:36:14--  https://raw.githubusercontent.com/Lavabar/kaggle_Herbarium22/main/efficientnet.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 7517 (7.3K) [text/plain]\r\n",
      "Saving to: ‘efficientnet.py’\r\n",
      "\r\n",
      "efficientnet.py     100%[===================>]   7.34K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-04-16 19:36:14 (42.3 MB/s) - ‘efficientnet.py’ saved [7517/7517]\r\n",
      "\r\n",
      "--2022-04-16 19:36:15--  https://github.com/Lavabar/kaggle_Herbarium22/raw/2a66a174217fae8ac69da232f6e6dd5407faeeb0/checkpoint0_7000.pth\r\n",
      "Resolving github.com (github.com)... 140.82.112.3\r\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/Lavabar/kaggle_Herbarium22/2a66a174217fae8ac69da232f6e6dd5407faeeb0/checkpoint0_7000.pth [following]\r\n",
      "--2022-04-16 19:36:15--  https://raw.githubusercontent.com/Lavabar/kaggle_Herbarium22/2a66a174217fae8ac69da232f6e6dd5407faeeb0/checkpoint0_7000.pth\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 45068933 (43M) [application/octet-stream]\r\n",
      "Saving to: ‘checkpoint0_7000.pth’\r\n",
      "\r\n",
      "checkpoint0_7000.pt 100%[===================>]  42.98M   177MB/s    in 0.2s    \r\n",
      "\r\n",
      "2022-04-16 19:36:18 (177 MB/s) - ‘checkpoint0_7000.pth’ saved [45068933/45068933]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Lavabar/kaggle_Herbarium22/main/efficientnet.py\n",
    "!wget https://github.com/Lavabar/kaggle_Herbarium22/raw/2a66a174217fae8ac69da232f6e6dd5407faeeb0/checkpoint0_7000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9a6b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:18.423347Z",
     "iopub.status.busy": "2022-04-16T19:36:18.422947Z",
     "iopub.status.idle": "2022-04-16T19:36:20.772838Z",
     "shell.execute_reply": "2022-04-16T19:36:20.771642Z"
    },
    "papermill": {
     "duration": 2.372733,
     "end_time": "2022-04-16T19:36:20.776187",
     "exception": false,
     "start_time": "2022-04-16T19:36:18.403454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from efficientnet import EfficientNetB0, EfficientNetB3\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "torch.manual_seed(0)\n",
    "images_path = '../input/herbarium-2022-fgvc9/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3c16a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:20.816228Z",
     "iopub.status.busy": "2022-04-16T19:36:20.815956Z",
     "iopub.status.idle": "2022-04-16T19:36:20.886892Z",
     "shell.execute_reply": "2022-04-16T19:36:20.885230Z"
    },
    "papermill": {
     "duration": 0.094755,
     "end_time": "2022-04-16T19:36:20.889982",
     "exception": false,
     "start_time": "2022-04-16T19:36:20.795227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a1c3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:20.928936Z",
     "iopub.status.busy": "2022-04-16T19:36:20.928148Z",
     "iopub.status.idle": "2022-04-16T19:36:20.934547Z",
     "shell.execute_reply": "2022-04-16T19:36:20.933572Z"
    },
    "papermill": {
     "duration": 0.027935,
     "end_time": "2022-04-16T19:36:20.936879",
     "exception": false,
     "start_time": "2022-04-16T19:36:20.908944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FirstModelFeatureExtractor(object):\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.model = torch.load(model_path)\n",
    "        self.model.eval()\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        #print(f'{sample.shape}')\n",
    "        res = self.model.feature_extractor(torch.unsqueeze(sample, 0).cuda())\n",
    "        #print(f'{res.shape}')\n",
    "        return torch.squeeze(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c15bd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:20.979953Z",
     "iopub.status.busy": "2022-04-16T19:36:20.978773Z",
     "iopub.status.idle": "2022-04-16T19:36:25.051943Z",
     "shell.execute_reply": "2022-04-16T19:36:25.051002Z"
    },
    "papermill": {
     "duration": 4.097264,
     "end_time": "2022-04-16T19:36:25.054569",
     "exception": false,
     "start_time": "2022-04-16T19:36:20.957305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose([\n",
    "                                transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                                FirstModelFeatureExtractor('./checkpoint0_7000.pth')\n",
    "                            ])\n",
    "\n",
    "class CategoryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe_X, dataframe_Y, transform, keys):\n",
    "        self.dataframe = dataframe_X.merge(dataframe_Y)\n",
    "        self.transform = transform\n",
    "        self.keys = keys\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.dataframe.iloc[index]\n",
    "        #print(row[\"file_name\"])\n",
    "        return (\n",
    "            transform(Image.open(images_path + row[\"file_name\"])).cuda(),\n",
    "            torch.tensor(self.keys[row[\"category_id\"]]).cuda()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af8e692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:25.093584Z",
     "iopub.status.busy": "2022-04-16T19:36:25.093298Z",
     "iopub.status.idle": "2022-04-16T19:36:25.103100Z",
     "shell.execute_reply": "2022-04-16T19:36:25.101947Z"
    },
    "papermill": {
     "duration": 0.031448,
     "end_time": "2022-04-16T19:36:25.105329",
     "exception": false,
     "start_time": "2022-04-16T19:36:25.073881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_training(training_loader, net, family_id, n_epoch=1):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(training_loader, 0):\n",
    "            # basic training loop\n",
    "            inputs, labels = data\n",
    "            print(inputs.shape)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('{}, Batch {}'.format(family_id, i + 1))\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:# Every 50 mini-batches...\n",
    "                torch.save(net, f'./checkpoint{family_id}_{epoch}_{i+1}.pth')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c095c3ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:25.141640Z",
     "iopub.status.busy": "2022-04-16T19:36:25.141230Z",
     "iopub.status.idle": "2022-04-16T19:36:25.221434Z",
     "shell.execute_reply": "2022-04-16T19:36:25.220223Z"
    },
    "papermill": {
     "duration": 0.102223,
     "end_time": "2022-04-16T19:36:25.224915",
     "exception": false,
     "start_time": "2022-04-16T19:36:25.122692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "fam_ids = sorted(os.listdir('../input/herbarium22-family-split/dataset_fsplit/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e4e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T19:36:25.268572Z",
     "iopub.status.busy": "2022-04-16T19:36:25.267695Z",
     "iopub.status.idle": "2022-04-16T21:43:52.749541Z",
     "shell.execute_reply": "2022-04-16T21:43:52.747987Z"
    },
    "papermill": {
     "duration": 7647.507081,
     "end_time": "2022-04-16T21:43:52.752075",
     "exception": false,
     "start_time": "2022-04-16T19:36:25.244994",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for family_id in fam_ids[195:]:\n",
    "\n",
    "    train_X = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/train_X.csv')\n",
    "    train_Y = pd.read_csv(f'../input/herbarium22-family-split/dataset_fsplit/{family_id}/train_Y.csv')\n",
    "\n",
    "    n_categories = train_Y.nunique()['category_id']\n",
    "\n",
    "    keys = dict(zip(sorted(train_Y['category_id'].unique()), range(n_categories)))\n",
    "    print(keys)\n",
    "\n",
    "    train_dataset = CategoryDataset(train_X, train_Y, transform, keys)\n",
    "\n",
    "    training_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                  batch_size=64,\n",
    "                                                  shuffle=False,\n",
    "                                                  drop_last=True)\n",
    "\n",
    "\n",
    "    net = EfficientNetB0(in_sz=1536, out_sz=n_categories)\n",
    "    net.to(device)\n",
    "\n",
    "    net = do_training(training_loader, net, family_id)\n",
    "    torch.save(net, f'./checkpoint_{family_id}_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebe3e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-16T21:43:55.080875Z",
     "iopub.status.busy": "2022-04-16T21:43:55.080543Z",
     "iopub.status.idle": "2022-04-16T21:44:30.344681Z",
     "shell.execute_reply": "2022-04-16T21:44:30.343420Z"
    },
    "papermill": {
     "duration": 36.5646,
     "end_time": "2022-04-16T21:44:30.347465",
     "exception": false,
     "start_time": "2022-04-16T21:43:53.782865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpoint_70_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_71_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_72_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_73_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_74_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_75_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_76_final.pth (deflated 9%)\r\n",
      "  adding: checkpoint_77_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_78_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_79_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_81_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_83_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_84_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_85_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_86_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_87_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_88_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_89_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_8_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_90_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_91_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_92_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_93_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_94_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_96_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_97_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_98_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_99_final.pth (deflated 8%)\r\n",
      "  adding: checkpoint_9_final.pth (deflated 8%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r -9 models_.zip ./checkpoint_*_final.pth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7712.954713,
   "end_time": "2022-04-16T21:44:34.363042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-16T19:36:01.408329",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}